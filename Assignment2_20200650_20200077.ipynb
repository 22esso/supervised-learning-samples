{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.datasets import mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def standardize(data, ax):\n",
    "    mean = np.sum(data, axis=ax) / len(data)\n",
    "    variance = np.sum((data - mean) ** 2) / len(data)\n",
    "    std_deviation = np.sqrt(variance)\n",
    "\n",
    "    standardized_data = (data - mean) / std_deviation\n",
    "    return standardized_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def K_fold(data, K=5):\n",
    "    fold_size = data.shape[0] // K\n",
    "    folds = np.zeros([K, fold_size, 785])\n",
    "    ready_data = np.array(data, dtype=object)\n",
    "    for i in range(K):\n",
    "        indices = np.random.choice(ready_data.shape[0], size=fold_size, replace=False)\n",
    "        work_fold = ready_data[indices]\n",
    "        folds[i] = np.array(work_fold)\n",
    "        ready_data = np.delete(ready_data, indices, axis=0)\n",
    "    folds = np.array(folds)\n",
    "    return folds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def rand_weights(size):\n",
    "    return np.random.uniform(-1, 1, size=size)\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    X = [(1 / (1 + np.exp(-z))) for z in x]\n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "class LogisticRegression():\n",
    "    def __init__(self, learning_rate=0.05, maxIter=1000, error_ratio=0.01, L1=0, batch_size=16, beta_1=0.9, beta_2=0.9,\n",
    "                 epsilon=0.5):\n",
    "        self.__epsilon = epsilon\n",
    "        self.__beta_2 = beta_2\n",
    "        self.__beta_1 = beta_1\n",
    "        self.__learning_rate = learning_rate\n",
    "        self.__maxIter = maxIter\n",
    "        self.__weigths = None\n",
    "        self.__bias = 0\n",
    "        self.__error_ratio = error_ratio\n",
    "        self.__L1 = L1\n",
    "        self.__batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, Y, optimizer=\"None\"):\n",
    "        sample_size = np.array(X).shape[0]\n",
    "        n_features = np.array(X).shape[1]\n",
    "        # self.__weigths = np.zeros(n_features)\n",
    "        self.__weigths = rand_weights(n_features)\n",
    "\n",
    "        Error = 1\n",
    "        if self.__batch_size > 1:\n",
    "            batches = np.random.choice(len(X), size=[sample_size // self.__batch_size, self.__batch_size],\n",
    "                                       replace=False)\n",
    "            batched_data = np.array(X[batches])\n",
    "            batched_labels = np.array(Y[batches])\n",
    "        else:\n",
    "            batched_data = np.array(X).reshape(1, sample_size, n_features)\n",
    "            batched_labels = np.array(Y).reshape(1, -1)\n",
    "\n",
    "        m_dw = np.zeros_like(self.__weigths)\n",
    "        v_dw = np.zeros_like(self.__weigths)\n",
    "        m_db = 0\n",
    "        v_db = 0\n",
    "        t = 0\n",
    "\n",
    "        for i in range(self.__maxIter):\n",
    "            epoch_bar = tqdm(total=sample_size // self.__batch_size, desc=f\"Epochs {i + 1}/{self.__maxIter}\")\n",
    "            for I in range(len(batched_data)):\n",
    "                epoch_bar.update(1)\n",
    "                epoch_bar.set_postfix({'accuracy': f'{1 - Error:.3f}'})\n",
    "\n",
    "                linear = np.dot(batched_data[I], self.__weigths) + self.__bias\n",
    "                prediction = sigmoid(linear)\n",
    "                dw = (1 / self.__batch_size) * np.dot(batched_data[I].T, (prediction - batched_labels[I])) + (\n",
    "                        self.__L1 / sample_size) * np.sum(np.abs(self.__weigths))\n",
    "                db = (1 / self.__batch_size) * np.sum(prediction - batched_labels[I])\n",
    "\n",
    "                t += 1\n",
    "                if optimizer == \"adam\":\n",
    "                    if len(dw.shape)>1:\n",
    "                        dw=np.sum(dw,axis=1)\n",
    "                    m_dw = self.__beta_1 * m_dw + (1 - self.__beta_1) * dw\n",
    "                    m_db = self.__beta_1 * m_db + (1 - self.__beta_1) * db\n",
    "                    v_dw = self.__beta_2 * v_dw + (1 - self.__beta_2) * (dw ** 2)\n",
    "                    v_db = self.__beta_2 * v_db + (1 - self.__beta_2) * (db ** 2)\n",
    "\n",
    "                    # Bias correction\n",
    "                    v_dw_hat = v_dw / (1 - self.__beta_2 ** t)\n",
    "                    v_db_hat = v_db / (1 - self.__beta_2 ** t)\n",
    "                    m_dw_hat = m_dw / (1 - self.__beta_1 ** t)\n",
    "                    m_db_hat = m_db / (1 - self.__beta_1 ** t)\n",
    "\n",
    "                    self.__weigths = self.__weigths - self.__learning_rate * m_dw_hat / (\n",
    "                                np.sqrt(v_dw_hat) + self.__epsilon)\n",
    "                    self.__bias = self.__bias - self.__learning_rate * m_db_hat / (np.sqrt(v_db_hat) + self.__epsilon)\n",
    "\n",
    "                elif optimizer == \"rms\":\n",
    "                    if len(dw.shape)>1:\n",
    "                        dw=np.sum(dw,axis=1)\n",
    "                    v_dw = self.__beta_2 * v_dw + (1 - self.__beta_2) * (dw ** 2)\n",
    "                    v_db = self.__beta_2 * v_db + (1 - self.__beta_2) * (db ** 2)\n",
    "\n",
    "                    # Bias correction\n",
    "                    v_dw_hat = v_dw / (1 - self.__beta_2 ** t)\n",
    "                    v_db_hat = v_db / (1 - self.__beta_2 ** t)\n",
    "\n",
    "                    self.__weigths = self.__weigths - self.__learning_rate * dw / (np.sqrt(v_dw_hat) + self.__epsilon)\n",
    "                    self.__bias = self.__bias - self.__learning_rate * db / (np.sqrt(v_db_hat) + self.__epsilon)\n",
    "\n",
    "                elif optimizer == \"None\":\n",
    "                    if len(dw.shape)>1:\n",
    "                        dw=np.sum(dw,axis=1)\n",
    "                    self.__weigths = self.__weigths - self.__learning_rate * dw\n",
    "                    self.__bias = self.__bias - self.__learning_rate * db\n",
    "\n",
    "                Error = abs(self._error(prediction, batched_labels[I], self.__L1))\n",
    "                if self.__error_ratio > Error:\n",
    "                    break\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        linear = np.dot(X_test, self.__weigths) + self.__bias\n",
    "        Y_predicted = sigmoid(linear)\n",
    "        class_f = [1 if y > 0.5 else 0 for y in Y_predicted]\n",
    "        return class_f\n",
    "\n",
    "    def evaluate(self, X_test, Y_test):\n",
    "        res = self.predict(X_test)\n",
    "        acc = 0\n",
    "        for i in range(len(res)):\n",
    "            if res[i] == Y_test[i]:\n",
    "                acc += 1\n",
    "        return acc / len(Y_test)\n",
    "\n",
    "    def _error(self, H, Y, L1=0):\n",
    "        er = np.mean(((Y * np.log(H)) + ((1 - Y) * np.log(1 - H))) + (L1 / len(H)) * np.sum(np.abs(self.__weigths)))\n",
    "        return er\n",
    "\n",
    "    def get_weights(self):\n",
    "        return self.__weigths\n",
    "\n",
    "    def set_weights(self, weigths):\n",
    "        self.__weigths = weigths"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_test, y_test, l_r, L1):\n",
    "    model = LogisticRegression(learning_rate=l_r, maxIter=10, L1=L1, error_ratio=0.0001)\n",
    "    model.fit(x_train, y_train, optimizer=\"rsm\")\n",
    "    acc = model.evaluate(x_test, y_test)\n",
    "    return acc, model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_X = np.array(train_X)\n",
    "train_y = np.array(train_y)\n",
    "test_X = np.array(test_X)\n",
    "test_y = np.array(test_y)\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12665, 28, 28) (12665, 1) (2115, 28, 28) (2115, 1)\n"
     ]
    }
   ],
   "source": [
    "train_X = np.append(train_X[np.where(train_y == 0)], train_X[np.where(train_y == 1)], axis=0)\n",
    "train_y = np.append(train_y[np.where(train_y == 0)], train_y[np.where(train_y == 1)], axis=0).reshape(-1, 1)\n",
    "test_X = np.append(test_X[np.where(test_y == 0)], test_X[np.where(test_y == 1)], axis=0)\n",
    "test_y = np.append(test_y[np.where(test_y == 0)], test_y[np.where(test_y == 1)], axis=0).reshape(-1, 1)\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12665, 784) (2115, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_X.reshape(-1, 28 * 28)\n",
    "x_train = np.array(standardize(x_train, 0))\n",
    "x_test = test_X.reshape(-1, 28 * 28)\n",
    "x_test = np.array(standardize(x_test, 0))\n",
    "print(x_train.shape, x_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# train_data = np.append(x_train, train_y, axis=1)\n",
    "# print(train_data.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# learning_rates = [0.1, 0.01, 0.001, 0.0001]\n",
    "# validation_accuarcy = []\n",
    "# test_accuarcy = []\n",
    "# models = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# for i in learning_rates:\n",
    "#     training = K_fold(train_data, 10)\n",
    "#     for j in range(10):\n",
    "#         val = training[j]\n",
    "#         x_val = np.array(val[:, 0:784])\n",
    "#         y_val = np.array(val[:, 784])\n",
    "#\n",
    "#         train = np.delete(training, j, axis=0).reshape(-1, 785)\n",
    "#         x_train = np.array(train[:, 0:784])\n",
    "#         y_train = np.array(train[:, 784])\n",
    "#\n",
    "#         Acc, Model = model(x_train, y_train, x_val, y_val, i, 0)\n",
    "#\n",
    "#         validation_accuarcy.append(Acc)\n",
    "#         models.append(Model.get_weights())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Max = max(validation_accuarcy)\n",
    "# idx = validation_accuarcy.index(Max)\n",
    "# weights = models[idx]\n",
    "# learning_rate = learning_rates[(idx // 10)]\n",
    "# print(Max, idx, learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# cls = LogisticRegression(learning_rate=learning_rate)\n",
    "# cls.set_weights(weights)\n",
    "# predictions = cls.predict(x_test)\n",
    "# print(f\"acc on test = {accuracy(predictions, test_y)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epochs 1/10:   0%|          | 0/197 [00:00<?, ?it/s]\u001B[A\n",
      "Epochs 1/10:   1%|          | 1/197 [00:00<00:00, 1003.42it/s, accuracy=0.000]\u001B[A\n",
      "Epochs 1/10:   1%|          | 2/197 [00:00<00:00, 399.86it/s, accuracy=0.276] \u001B[A\n",
      "Epochs 1/10:   2%|▏         | 3/197 [00:00<00:00, 374.80it/s, accuracy=0.185]\u001B[A\n",
      "Epochs 1/10:   2%|▏         | 4/197 [00:00<00:00, 306.04it/s, accuracy=0.108]\u001B[A\n",
      "Epochs 1/10:   3%|▎         | 5/197 [00:00<00:00, 276.99it/s, accuracy=-0.050]\u001B[A\n",
      "Epochs 1/10:   3%|▎         | 6/197 [00:00<00:00, 272.45it/s, accuracy=-0.224]\u001B[A\n",
      "Epochs 1/10:   4%|▎         | 7/197 [00:00<00:00, 273.43it/s, accuracy=-0.344]\u001B[A\n",
      "Epochs 1/10:   4%|▍         | 8/197 [00:00<00:00, 253.41it/s, accuracy=-0.447]\u001B[A\n",
      "Epochs 1/10:   5%|▍         | 9/197 [00:00<00:00, 253.00it/s, accuracy=-0.818]\u001B[A\n",
      "Epochs 1/10:   5%|▌         | 10/197 [00:00<00:00, 259.23it/s, accuracy=-0.926]\u001B[A\n",
      "Epochs 1/10:   6%|▌         | 11/197 [00:00<00:00, 258.38it/s, accuracy=-1.014]\u001B[A\n",
      "Epochs 1/10:   6%|▌         | 12/197 [00:00<00:00, 252.23it/s, accuracy=-1.485]\u001B[A\n",
      "Epochs 1/10:   7%|▋         | 13/197 [00:00<00:00, 252.08it/s, accuracy=-1.657]\u001B[A\n",
      "Epochs 1/10:   7%|▋         | 14/197 [00:00<00:01, 98.22it/s, accuracy=-1.657] \u001B[A\n",
      "Epochs 1/10:   7%|▋         | 14/197 [00:00<00:01, 98.22it/s, accuracy=-1.908]\u001B[A\n",
      "Epochs 1/10:   8%|▊         | 15/197 [00:00<00:01, 98.22it/s, accuracy=-2.213]\u001B[A\n",
      "Epochs 1/10:   8%|▊         | 16/197 [00:00<00:01, 98.22it/s, accuracy=-2.564]\u001B[A\n",
      "Epochs 1/10:   9%|▊         | 17/197 [00:00<00:01, 98.22it/s, accuracy=-2.418]\u001B[A\n",
      "Epochs 1/10:   9%|▉         | 18/197 [00:00<00:01, 98.22it/s, accuracy=-2.922]\u001B[A\n",
      "Epochs 1/10:  10%|▉         | 19/197 [00:00<00:01, 98.22it/s, accuracy=-2.767]\u001B[A\n",
      "Epochs 1/10:  10%|█         | 20/197 [00:00<00:01, 98.22it/s, accuracy=-3.278]\u001B[A\n",
      "Epochs 1/10:  11%|█         | 21/197 [00:00<00:01, 98.22it/s, accuracy=-3.138]\u001B[A\n",
      "Epochs 1/10:  11%|█         | 22/197 [00:00<00:01, 98.22it/s, accuracy=-3.755]\u001B[A\n",
      "Epochs 1/10:  12%|█▏        | 23/197 [00:00<00:01, 98.22it/s, accuracy=-3.674]\u001B[A\n",
      "Epochs 1/10:  12%|█▏        | 24/197 [00:00<00:01, 98.22it/s, accuracy=-4.117]\u001B[A\n",
      "Epochs 1/10:  13%|█▎        | 25/197 [00:00<00:01, 98.22it/s, accuracy=-3.852]\u001B[A\n",
      "Epochs 1/10:  13%|█▎        | 26/197 [00:00<00:01, 98.22it/s, accuracy=-4.013]\u001B[A\n",
      "Epochs 1/10:  14%|█▎        | 27/197 [00:00<00:01, 98.22it/s, accuracy=-4.633]\u001B[A\n",
      "Epochs 1/10:  14%|█▍        | 28/197 [00:00<00:01, 98.22it/s, accuracy=-4.668]\u001B[A\n",
      "Epochs 1/10:  15%|█▍        | 29/197 [00:00<00:01, 98.22it/s, accuracy=-5.292]\u001B[A\n",
      "Epochs 1/10:  15%|█▌        | 30/197 [00:00<00:01, 98.22it/s, accuracy=-5.199]\u001B[A\n",
      "Epochs 1/10:  16%|█▌        | 31/197 [00:00<00:01, 98.22it/s, accuracy=-4.834]\u001B[A\n",
      "Epochs 1/10:  16%|█▌        | 32/197 [00:00<00:01, 98.22it/s, accuracy=-5.786]\u001B[A\n",
      "Epochs 1/10:  17%|█▋        | 33/197 [00:00<00:01, 98.22it/s, accuracy=-5.968]\u001B[A\n",
      "Epochs 1/10:  17%|█▋        | 34/197 [00:00<00:01, 148.47it/s, accuracy=-5.968]\u001B[A\n",
      "Epochs 1/10:  17%|█▋        | 34/197 [00:00<00:01, 148.47it/s, accuracy=-5.893]\u001B[A\n",
      "Epochs 1/10:  18%|█▊        | 35/197 [00:00<00:01, 148.47it/s, accuracy=-5.698]\u001B[A\n",
      "Epochs 1/10:  18%|█▊        | 36/197 [00:00<00:01, 148.47it/s, accuracy=-6.613]\u001B[A\n",
      "Epochs 1/10:  19%|█▉        | 37/197 [00:00<00:01, 148.47it/s, accuracy=-6.699]\u001B[A\n",
      "Epochs 1/10:  19%|█▉        | 38/197 [00:00<00:01, 148.47it/s, accuracy=-6.186]\u001B[A\n",
      "Epochs 1/10:  20%|█▉        | 39/197 [00:00<00:01, 148.47it/s, accuracy=-7.384]\u001B[A\n",
      "Epochs 1/10:  20%|██        | 40/197 [00:00<00:01, 148.47it/s, accuracy=-7.587]\u001B[A\n",
      "Epochs 1/10:  21%|██        | 41/197 [00:00<00:01, 148.47it/s, accuracy=-7.722]\u001B[A\n",
      "Epochs 1/10:  21%|██▏       | 42/197 [00:00<00:01, 148.47it/s, accuracy=-8.356]\u001B[A\n",
      "Epochs 1/10:  22%|██▏       | 43/197 [00:00<00:01, 148.47it/s, accuracy=-7.774]\u001B[A\n",
      "Epochs 1/10:  22%|██▏       | 44/197 [00:00<00:01, 148.47it/s, accuracy=-8.560]\u001B[A\n",
      "Epochs 1/10:  23%|██▎       | 45/197 [00:00<00:01, 148.47it/s, accuracy=-8.668]\u001B[A\n",
      "Epochs 1/10:  23%|██▎       | 46/197 [00:00<00:01, 148.47it/s, accuracy=-8.350]\u001B[A\n",
      "Epochs 1/10:  24%|██▍       | 47/197 [00:00<00:01, 148.47it/s, accuracy=-9.079]\u001B[A\n",
      "Epochs 1/10:  24%|██▍       | 48/197 [00:00<00:01, 148.47it/s, accuracy=-8.653]\u001B[A\n",
      "Epochs 1/10:  25%|██▍       | 49/197 [00:00<00:00, 148.47it/s, accuracy=-10.382]\u001B[A\n",
      "Epochs 1/10:  25%|██▌       | 50/197 [00:00<00:00, 148.47it/s, accuracy=-10.960]\u001B[A\n",
      "Epochs 1/10:  26%|██▌       | 51/197 [00:00<00:00, 148.47it/s, accuracy=-9.931] \u001B[A\n",
      "Epochs 1/10:  26%|██▋       | 52/197 [00:00<00:00, 148.47it/s, accuracy=-10.244]\u001B[A\n",
      "Epochs 1/10:  27%|██▋       | 53/197 [00:00<00:00, 148.47it/s, accuracy=-9.921] \u001B[A\n",
      "Epochs 1/10:  27%|██▋       | 54/197 [00:00<00:00, 148.47it/s, accuracy=-10.709]\u001B[A\n",
      "Epochs 1/10:  28%|██▊       | 55/197 [00:00<00:00, 148.47it/s, accuracy=-11.201]\u001B[A\n",
      "Epochs 1/10:  28%|██▊       | 56/197 [00:00<00:00, 148.47it/s, accuracy=-11.153]\u001B[A\n",
      "Epochs 1/10:  29%|██▉       | 57/197 [00:00<00:00, 148.47it/s, accuracy=-11.873]\u001B[A\n",
      "Epochs 1/10:  29%|██▉       | 58/197 [00:00<00:00, 148.47it/s, accuracy=-10.211]\u001B[A\n",
      "Epochs 1/10:  30%|██▉       | 59/197 [00:00<00:00, 148.47it/s, accuracy=-12.323]\u001B[A\n",
      "Epochs 1/10:  30%|███       | 60/197 [00:00<00:00, 193.62it/s, accuracy=-12.323]\u001B[A\n",
      "Epochs 1/10:  30%|███       | 60/197 [00:00<00:00, 193.62it/s, accuracy=-12.612]\u001B[A\n",
      "Epochs 1/10:  31%|███       | 61/197 [00:00<00:00, 193.62it/s, accuracy=-12.181]\u001B[A\n",
      "Epochs 1/10:  31%|███▏      | 62/197 [00:00<00:00, 193.62it/s, accuracy=-12.197]\u001B[A\n",
      "Epochs 1/10:  32%|███▏      | 63/197 [00:00<00:00, 193.62it/s, accuracy=-12.500]\u001B[A\n",
      "Epochs 1/10:  32%|███▏      | 64/197 [00:00<00:00, 193.62it/s, accuracy=-12.717]\u001B[A\n",
      "Epochs 1/10:  33%|███▎      | 65/197 [00:00<00:00, 193.62it/s, accuracy=-12.371]\u001B[A\n",
      "Epochs 1/10:  34%|███▎      | 66/197 [00:00<00:00, 193.62it/s, accuracy=-13.806]\u001B[A\n",
      "Epochs 1/10:  34%|███▍      | 67/197 [00:00<00:00, 193.62it/s, accuracy=-13.458]\u001B[A\n",
      "Epochs 1/10:  35%|███▍      | 68/197 [00:00<00:00, 193.62it/s, accuracy=-12.848]\u001B[A\n",
      "Epochs 1/10:  35%|███▌      | 69/197 [00:00<00:00, 193.62it/s, accuracy=-13.375]\u001B[A\n",
      "Epochs 1/10:  36%|███▌      | 70/197 [00:00<00:00, 193.62it/s, accuracy=-14.855]\u001B[A\n",
      "Epochs 1/10:  36%|███▌      | 71/197 [00:00<00:00, 193.62it/s, accuracy=-14.896]\u001B[A\n",
      "Epochs 1/10:  37%|███▋      | 72/197 [00:00<00:00, 193.62it/s, accuracy=-14.304]\u001B[A\n",
      "Epochs 1/10:  37%|███▋      | 73/197 [00:00<00:00, 193.62it/s, accuracy=-16.755]\u001B[A\n",
      "Epochs 1/10:  38%|███▊      | 74/197 [00:00<00:00, 193.62it/s, accuracy=-16.338]\u001B[A\n",
      "Epochs 1/10:  38%|███▊      | 75/197 [00:00<00:00, 193.62it/s, accuracy=-15.937]\u001B[A\n",
      "Epochs 1/10:  39%|███▊      | 76/197 [00:00<00:00, 193.62it/s, accuracy=-16.237]\u001B[AC:\\Users\\Kagero\\AppData\\Local\\Temp\\ipykernel_10492\\804840043.py:115: RuntimeWarning: divide by zero encountered in log\n",
      "  er = np.mean(((Y * np.log(H)) + ((1 - Y) * np.log(1 - H))) + (L1 / len(H)) * np.sum(np.abs(self.__weigths)))\n",
      "C:\\Users\\Kagero\\AppData\\Local\\Temp\\ipykernel_10492\\804840043.py:115: RuntimeWarning: invalid value encountered in multiply\n",
      "  er = np.mean(((Y * np.log(H)) + ((1 - Y) * np.log(1 - H))) + (L1 / len(H)) * np.sum(np.abs(self.__weigths)))\n",
      "\n",
      "Epochs 1/10:  39%|███▉      | 77/197 [00:00<00:00, 193.62it/s, accuracy=nan]    \u001B[A\n",
      "Epochs 1/10:  40%|███▉      | 78/197 [00:00<00:00, 193.62it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  40%|████      | 79/197 [00:00<00:00, 193.62it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  41%|████      | 80/197 [00:00<00:00, 193.62it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  41%|████      | 81/197 [00:00<00:00, 193.62it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  42%|████▏     | 82/197 [00:00<00:00, 193.62it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  42%|████▏     | 83/197 [00:00<00:00, 193.62it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  43%|████▎     | 84/197 [00:00<00:00, 193.62it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  43%|████▎     | 85/197 [00:00<00:00, 193.62it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  44%|████▎     | 86/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  44%|████▎     | 86/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  44%|████▍     | 87/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  45%|████▍     | 88/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  45%|████▌     | 89/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  46%|████▌     | 90/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  46%|████▌     | 91/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  47%|████▋     | 92/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  47%|████▋     | 93/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  48%|████▊     | 94/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  48%|████▊     | 95/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  49%|████▊     | 96/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  49%|████▉     | 97/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  50%|████▉     | 98/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  50%|█████     | 99/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  51%|█████     | 100/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  51%|█████▏    | 101/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  52%|█████▏    | 102/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  52%|█████▏    | 103/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  53%|█████▎    | 104/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  53%|█████▎    | 105/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  54%|█████▍    | 106/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  54%|█████▍    | 107/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  55%|█████▍    | 108/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  55%|█████▌    | 109/197 [00:00<00:00, 217.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  56%|█████▌    | 110/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  56%|█████▌    | 110/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  56%|█████▋    | 111/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  57%|█████▋    | 112/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  57%|█████▋    | 113/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  58%|█████▊    | 114/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  58%|█████▊    | 115/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  59%|█████▉    | 116/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  59%|█████▉    | 117/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  60%|█████▉    | 118/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  60%|██████    | 119/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  61%|██████    | 120/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  61%|██████▏   | 121/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  62%|██████▏   | 122/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  62%|██████▏   | 123/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  63%|██████▎   | 124/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  63%|██████▎   | 125/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  64%|██████▍   | 126/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  64%|██████▍   | 127/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  65%|██████▍   | 128/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  65%|██████▌   | 129/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  66%|██████▌   | 130/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  66%|██████▋   | 131/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  67%|██████▋   | 132/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  68%|██████▊   | 133/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  68%|██████▊   | 134/197 [00:00<00:00, 221.70it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  69%|██████▊   | 135/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  69%|██████▊   | 135/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  69%|██████▉   | 136/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  70%|██████▉   | 137/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  70%|███████   | 138/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  71%|███████   | 139/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  71%|███████   | 140/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  72%|███████▏  | 141/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  72%|███████▏  | 142/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  73%|███████▎  | 143/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  73%|███████▎  | 144/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  74%|███████▎  | 145/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  74%|███████▍  | 146/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  75%|███████▍  | 147/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  75%|███████▌  | 148/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  76%|███████▌  | 149/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  76%|███████▌  | 150/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  77%|███████▋  | 151/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  77%|███████▋  | 152/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  78%|███████▊  | 153/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  78%|███████▊  | 154/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  79%|███████▊  | 155/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  79%|███████▉  | 156/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  80%|███████▉  | 157/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  80%|████████  | 158/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  81%|████████  | 159/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  81%|████████  | 160/197 [00:00<00:00, 230.54it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  82%|████████▏ | 161/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  82%|████████▏ | 161/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  82%|████████▏ | 162/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  83%|████████▎ | 163/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  83%|████████▎ | 164/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  84%|████████▍ | 165/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  84%|████████▍ | 166/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  85%|████████▍ | 167/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  85%|████████▌ | 168/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  86%|████████▌ | 169/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  86%|████████▋ | 170/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  87%|████████▋ | 171/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  87%|████████▋ | 172/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  88%|████████▊ | 173/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  88%|████████▊ | 174/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  89%|████████▉ | 175/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  89%|████████▉ | 176/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  90%|████████▉ | 177/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  90%|█████████ | 178/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  91%|█████████ | 179/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  91%|█████████▏| 180/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  92%|█████████▏| 181/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  92%|█████████▏| 182/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  93%|█████████▎| 183/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  93%|█████████▎| 184/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  94%|█████████▍| 185/197 [00:00<00:00, 239.14it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  94%|█████████▍| 186/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  94%|█████████▍| 186/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  95%|█████████▍| 187/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  95%|█████████▌| 188/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  96%|█████████▌| 189/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  96%|█████████▋| 190/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  97%|█████████▋| 191/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  97%|█████████▋| 192/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  98%|█████████▊| 193/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  98%|█████████▊| 194/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  99%|█████████▉| 195/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10:  99%|█████████▉| 196/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "Epochs 1/10: 100%|██████████| 197/197 [00:00<00:00, 235.19it/s, accuracy=nan]\u001B[A\n",
      "\n",
      "Epochs 1/10: 100%|██████████| 197/197 [00:00<00:00, 216.19it/s, accuracy=nan]\n",
      "\n",
      "\n",
      "Epochs 2/10:   1%|          | 1/197 [00:00<00:00, 490.96it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   1%|          | 2/197 [00:00<00:00, 333.09it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   2%|▏         | 3/197 [00:00<00:00, 333.30it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   2%|▏         | 4/197 [00:00<00:00, 304.06it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   3%|▎         | 5/197 [00:00<00:00, 309.63it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   3%|▎         | 6/197 [00:00<00:00, 283.63it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   4%|▎         | 7/197 [00:00<00:00, 267.48it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   4%|▍         | 8/197 [00:00<00:00, 265.33it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   5%|▍         | 9/197 [00:00<00:00, 242.24it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   5%|▌         | 10/197 [00:00<00:00, 212.09it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   6%|▌         | 11/197 [00:00<00:00, 187.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   6%|▌         | 12/197 [00:00<00:00, 185.25it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   7%|▋         | 13/197 [00:00<00:01, 176.14it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   7%|▋         | 14/197 [00:00<00:01, 175.48it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   8%|▊         | 15/197 [00:00<00:01, 174.82it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   8%|▊         | 16/197 [00:00<00:01, 176.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   9%|▊         | 17/197 [00:00<00:01, 177.50it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   9%|▉         | 18/197 [00:00<00:01, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:   9%|▉         | 18/197 [00:00<00:01, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  10%|▉         | 19/197 [00:00<00:01, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  10%|█         | 20/197 [00:00<00:01, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  11%|█         | 21/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  11%|█         | 22/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  12%|█▏        | 23/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  12%|█▏        | 24/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  13%|█▎        | 25/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  13%|█▎        | 26/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  14%|█▎        | 27/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  14%|█▍        | 28/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  15%|█▍        | 29/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  15%|█▌        | 30/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  16%|█▌        | 31/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  16%|█▌        | 32/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  17%|█▋        | 33/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  17%|█▋        | 34/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  18%|█▊        | 35/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  18%|█▊        | 36/197 [00:00<00:00, 176.81it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  19%|█▉        | 37/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  19%|█▉        | 37/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  19%|█▉        | 38/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  20%|█▉        | 39/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  20%|██        | 40/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  21%|██        | 41/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  21%|██▏       | 42/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  22%|██▏       | 43/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  22%|██▏       | 44/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  23%|██▎       | 45/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  23%|██▎       | 46/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  24%|██▍       | 47/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  24%|██▍       | 48/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  25%|██▍       | 49/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  25%|██▌       | 50/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  26%|██▌       | 51/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  26%|██▋       | 52/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  27%|██▋       | 53/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  27%|██▋       | 54/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  28%|██▊       | 55/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  28%|██▊       | 56/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  29%|██▉       | 57/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  29%|██▉       | 58/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  30%|██▉       | 59/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  30%|███       | 60/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  31%|███       | 61/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  31%|███▏      | 62/197 [00:00<00:00, 181.67it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  32%|███▏      | 63/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  32%|███▏      | 63/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  32%|███▏      | 64/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  33%|███▎      | 65/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  34%|███▎      | 66/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  34%|███▍      | 67/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  35%|███▍      | 68/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  35%|███▌      | 69/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  36%|███▌      | 70/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  36%|███▌      | 71/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  37%|███▋      | 72/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  37%|███▋      | 73/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  38%|███▊      | 74/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  38%|███▊      | 75/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  39%|███▊      | 76/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  39%|███▉      | 77/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  40%|███▉      | 78/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  40%|████      | 79/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  41%|████      | 80/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  41%|████      | 81/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  42%|████▏     | 82/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  42%|████▏     | 83/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  43%|████▎     | 84/197 [00:00<00:00, 215.26it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  43%|████▎     | 85/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  43%|████▎     | 85/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  44%|████▎     | 86/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  44%|████▍     | 87/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  45%|████▍     | 88/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  45%|████▌     | 89/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  46%|████▌     | 90/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  46%|████▌     | 91/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  47%|████▋     | 92/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  47%|████▋     | 93/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  48%|████▊     | 94/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  48%|████▊     | 95/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  49%|████▊     | 96/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  49%|████▉     | 97/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  50%|████▉     | 98/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  50%|█████     | 99/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  51%|█████     | 100/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  51%|█████▏    | 101/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  52%|█████▏    | 102/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  52%|█████▏    | 103/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  53%|█████▎    | 104/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  53%|█████▎    | 105/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  54%|█████▍    | 106/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  54%|█████▍    | 107/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  55%|█████▍    | 108/197 [00:00<00:00, 213.70it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  55%|█████▌    | 109/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  55%|█████▌    | 109/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  56%|█████▌    | 110/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  56%|█████▋    | 111/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  57%|█████▋    | 112/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  57%|█████▋    | 113/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  58%|█████▊    | 114/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  58%|█████▊    | 115/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  59%|█████▉    | 116/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  59%|█████▉    | 117/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  60%|█████▉    | 118/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  60%|██████    | 119/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  61%|██████    | 120/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  61%|██████▏   | 121/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  62%|██████▏   | 122/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  62%|██████▏   | 123/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  63%|██████▎   | 124/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  63%|██████▎   | 125/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  64%|██████▍   | 126/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  64%|██████▍   | 127/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  65%|██████▍   | 128/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  65%|██████▌   | 129/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  66%|██████▌   | 130/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  66%|██████▋   | 131/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  67%|██████▋   | 132/197 [00:00<00:00, 222.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  68%|██████▊   | 133/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  68%|██████▊   | 133/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  68%|██████▊   | 134/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  69%|██████▊   | 135/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  69%|██████▉   | 136/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  70%|██████▉   | 137/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  70%|███████   | 138/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  71%|███████   | 139/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  71%|███████   | 140/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  72%|███████▏  | 141/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  72%|███████▏  | 142/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  73%|███████▎  | 143/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  73%|███████▎  | 144/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  74%|███████▎  | 145/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  74%|███████▍  | 146/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  75%|███████▍  | 147/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  75%|███████▌  | 148/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  76%|███████▌  | 149/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  76%|███████▌  | 150/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  77%|███████▋  | 151/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  77%|███████▋  | 152/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  78%|███████▊  | 153/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  78%|███████▊  | 154/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  79%|███████▊  | 155/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  79%|███████▉  | 156/197 [00:00<00:00, 226.16it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  80%|███████▉  | 157/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  80%|███████▉  | 157/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  80%|████████  | 158/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  81%|████████  | 159/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  81%|████████  | 160/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  82%|████████▏ | 161/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  82%|████████▏ | 162/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  83%|████████▎ | 163/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  83%|████████▎ | 164/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  84%|████████▍ | 165/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  84%|████████▍ | 166/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  85%|████████▍ | 167/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  85%|████████▌ | 168/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  86%|████████▌ | 169/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  86%|████████▋ | 170/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  87%|████████▋ | 171/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  87%|████████▋ | 172/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  88%|████████▊ | 173/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  88%|████████▊ | 174/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  89%|████████▉ | 175/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  89%|████████▉ | 176/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  90%|████████▉ | 177/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  90%|█████████ | 178/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  91%|█████████ | 179/197 [00:00<00:00, 229.46it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  91%|█████████▏| 180/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  91%|█████████▏| 180/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  92%|█████████▏| 181/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  92%|█████████▏| 182/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  93%|█████████▎| 183/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  93%|█████████▎| 184/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  94%|█████████▍| 185/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  94%|█████████▍| 186/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  95%|█████████▍| 187/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  95%|█████████▌| 188/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  96%|█████████▌| 189/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  96%|█████████▋| 190/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  97%|█████████▋| 191/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  97%|█████████▋| 192/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  98%|█████████▊| 193/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  98%|█████████▊| 194/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  99%|█████████▉| 195/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10:  99%|█████████▉| 196/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "\n",
      "Epochs 2/10: 100%|██████████| 197/197 [00:00<00:00, 221.44it/s, accuracy=nan]\u001B[A\u001B[A\n",
      "Epochs 2/10: 100%|██████████| 197/197 [00:00<00:00, 215.48it/s, accuracy=nan]\n",
      "\n",
      "Epochs 3/10:   1%|          | 1/197 [00:00<00:00, 497.90it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   1%|          | 2/197 [00:00<00:00, 285.36it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   2%|▏         | 3/197 [00:00<00:00, 299.37it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   2%|▏         | 4/197 [00:00<00:00, 306.77it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   3%|▎         | 5/197 [00:00<00:00, 293.92it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   3%|▎         | 6/197 [00:00<00:00, 285.46it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   4%|▎         | 7/197 [00:00<00:00, 269.03it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   4%|▍         | 8/197 [00:00<00:00, 266.53it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   5%|▍         | 9/197 [00:00<00:00, 257.02it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   5%|▌         | 10/197 [00:00<00:00, 256.27it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   6%|▌         | 11/197 [00:00<00:00, 249.90it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   6%|▌         | 12/197 [00:00<00:00, 255.23it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   7%|▋         | 13/197 [00:00<00:00, 245.20it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   7%|▋         | 14/197 [00:00<00:00, 241.24it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   8%|▊         | 15/197 [00:00<00:00, 238.06it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   8%|▊         | 16/197 [00:00<00:00, 231.53it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   9%|▊         | 17/197 [00:00<00:00, 235.75it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:   9%|▉         | 18/197 [00:00<00:00, 239.66it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  10%|▉         | 19/197 [00:00<00:00, 240.16it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  10%|█         | 20/197 [00:00<00:00, 237.79it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  11%|█         | 21/197 [00:00<00:00, 233.02it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  11%|█         | 22/197 [00:00<00:00, 228.88it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  12%|█▏        | 23/197 [00:00<00:00, 228.48it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  12%|█▏        | 24/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  12%|█▏        | 24/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  13%|█▎        | 25/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  13%|█▎        | 26/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  14%|█▎        | 27/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  14%|█▍        | 28/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  15%|█▍        | 29/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  15%|█▌        | 30/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  16%|█▌        | 31/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  16%|█▌        | 32/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  17%|█▋        | 33/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  17%|█▋        | 34/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  18%|█▊        | 35/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  18%|█▊        | 36/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  19%|█▉        | 37/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  19%|█▉        | 38/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  20%|█▉        | 39/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  20%|██        | 40/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  21%|██        | 41/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  21%|██▏       | 42/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  22%|██▏       | 43/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  22%|██▏       | 44/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  23%|██▎       | 45/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  23%|██▎       | 46/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  24%|██▍       | 47/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  24%|██▍       | 48/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  25%|██▍       | 49/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  25%|██▌       | 50/197 [00:00<00:00, 231.49it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  26%|██▌       | 51/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  26%|██▌       | 51/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  26%|██▋       | 52/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  27%|██▋       | 53/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  27%|██▋       | 54/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  28%|██▊       | 55/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  28%|██▊       | 56/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  29%|██▉       | 57/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  29%|██▉       | 58/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  30%|██▉       | 59/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  30%|███       | 60/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n",
      "Epochs 3/10:  31%|███       | 61/197 [00:00<00:00, 250.13it/s, accuracy=nan]\u001B[A\n"
     ]
    }
   ],
   "source": [
    "batch_model_1 = LogisticRegression(maxIter=10, batch_size=64)\n",
    "batch_model_1.fit(x_train, train_y)\n",
    "print(f\"Accuracy = {batch_model_1.evaluate(x_test, test_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_model_1 = LogisticRegression(maxIter=10, batch_size=1,L1=2)\n",
    "reg_model_1.fit(x_train, train_y)\n",
    "print(f\"Accuracy = {reg_model_1.evaluate(x_test, test_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_model_2 = LogisticRegression(maxIter=10, batch_size=1,L1=0.9)\n",
    "reg_model_2.fit(x_train, train_y)\n",
    "print(f\"Accuracy = {reg_model_2.evaluate(x_test, test_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_model_2 = LogisticRegression(maxIter=10, batch_size=32)\n",
    "batch_model_2.fit(x_train, train_y)\n",
    "print(f\"Accuracy = {batch_model_2.evaluate(x_test, test_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ADAM_model_2 = LogisticRegression(maxIter=10, batch_size=32)\n",
    "ADAM_model_2.fit(x_train, train_y,\"adam\")\n",
    "print(f\"Accuracy = {ADAM_model_2.evaluate(x_test, test_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RSM_model_2 = LogisticRegression(maxIter=10, batch_size=32)\n",
    "RSM_model_2.fit(x_train, train_y,\"rsm\")\n",
    "print(f\"Accuracy = {RSM_model_2.evaluate(x_test, test_y)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# the GD model with regylarization accuracy =0.9962174940898345\n",
    "# the mini batch GD with regularization model accuracy =\n",
    "# the RMS model accuracy =\n",
    "# ADMAS model accuracy=\n",
    "# it is clear that"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ]
}
