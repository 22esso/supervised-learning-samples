{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJmWOHyT5iZy"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ9zeg3J7wBW"
      },
      "outputs": [],
      "source": [
        "def standardize(data, ax):\n",
        "    mean = np.sum(data, axis=ax) / len(data)\n",
        "    variance = np.sum((data - mean) ** 2) / len(data)\n",
        "    std_deviation = np.sqrt(variance)\n",
        "\n",
        "    standardized_data = (data - mean) / std_deviation\n",
        "    return standardized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkMkqt8y55gK"
      },
      "outputs": [],
      "source": [
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk5AQb_95-xR",
        "outputId": "7ec188e6-3253-4555-a133-c9577ed92908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "train_X = np.array(train_X)\n",
        "train_y = np.array(train_y)\n",
        "test_X = np.array(test_X)\n",
        "test_y = np.array(test_y)\n",
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0Ae__Ch7TeI",
        "outputId": "c04ba852-0680-4e56-9302-fb86730136b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKKkkvRp7flq",
        "outputId": "71955613-5490-45e0-b929-4db49cd880ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 784) (10000, 784)\n"
          ]
        }
      ],
      "source": [
        "x_train = train_X.reshape(-1, 28 * 28)\n",
        "x_train = np.array(standardize(x_train, 0))\n",
        "x_test = test_X.reshape(-1, 28 * 28)\n",
        "x_test = np.array(standardize(x_test, 0))\n",
        "print(x_train.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi1NRn2HK221",
        "outputId": "eb6454aa-823a-485e-8377-023cf4cbe482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 10)\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from keras.utils import to_categorical\n",
        "test_y =np.array(to_categorical(test_y))\n",
        "print(test_y.shape)\n",
        "print(test_y[0]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldNIORgP79v0"
      },
      "outputs": [],
      "source": [
        "# test_y=test_y.reshape(-1, 10)\n",
        "# print(test_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRORsGM05ESE",
        "outputId": "39b9996b-3a75-4468-acaf-8786800948e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 784)\n"
          ]
        }
      ],
      "source": [
        "num_classes=test_y.shape[1]\n",
        "num_features=x_train.shape[1]\n",
        "weights = np.zeros((num_classes, num_features))\n",
        "print(weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXAJJGFHKPro"
      },
      "outputs": [],
      "source": [
        "def rand_weights(size):\n",
        "    dum = list()\n",
        "    for i in range(size):\n",
        "        dum.append(random.uniform(-1, 1))\n",
        "    return np.array(dum)\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    X = [(1 / (1 + np.exp(-z))) for z in x]\n",
        "    return np.array(X)\n",
        "\n",
        "\n",
        "def error(H, Y):\n",
        "    er = 0\n",
        "    for i in range(len(H)):\n",
        "        er = er + ((Y[i] * np.log(H[i])) + ((1 - Y[i]) * np.log(1 - H[i])))\n",
        "    return round(er / len((H)), 4)\n",
        "\n",
        "\n",
        "def accuracy(class_f, Y_test):\n",
        "    return (np.sum(class_f == Y_test) / len(Y_test)) * 100\n",
        "\n",
        "\n",
        "class LogisticRegression():\n",
        "    def __init__(self, learning_rate=0.05, maxIter=1000, error_ratio=0.01):\n",
        "        self.__learning_rate = learning_rate\n",
        "        self.__maxIter = maxIter\n",
        "        self.__weigths = None\n",
        "        self.__bias = 0\n",
        "        self.__error_ratio = error_ratio\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        sample_size = np.array(X).shape[0]\n",
        "        n_features = np.array(X).shape[1]\n",
        "        #self.__weigths = np.zeros(n_features)\n",
        "        self.__weigths = rand_weights(n_features)\n",
        "        Error = 1\n",
        "        epoch_bar = tqdm(desc='Epochs', total=self.__maxIter)\n",
        "        for i in range(self.__maxIter):\n",
        "            epoch_bar.update(1)\n",
        "            epoch_bar.set_postfix({'accuracy': f'{1 - Error:.3f}'})\n",
        "            linear = np.dot(X, self.__weigths) + self.__bias\n",
        "            prediction = sigmoid(linear)\n",
        "            dw = (1 / sample_size) * np.dot(X.T, (prediction - Y))\n",
        "            db = (1 / sample_size) * np.sum(prediction - Y)\n",
        "\n",
        "            self.__weigths = self.__weigths - self.__learning_rate * dw\n",
        "            self.__bias = self.__bias - self.__learning_rate * db\n",
        "            Error = abs(error(prediction, Y))\n",
        "            if self.__error_ratio > Error:\n",
        "                break\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        linear = np.dot(X_test, self.__weigths) + self.__bias\n",
        "        Y_predicted = sigmoid(linear)\n",
        "        class_f = [1 if y > 0.5 else 0 for y in Y_predicted]\n",
        "        return class_f\n",
        "\n",
        "    def get_weights(self):\n",
        "        return self.__weigths\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        self.__weigths = weights\n",
        "\n",
        "    def get_learning_rate(self):\n",
        "        return self.__learning_rate\n",
        "\n",
        "    def set_learning_rate(self, learning_rate):\n",
        "        self.__learning_rate = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEaAmZD0N9yD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfVQtIaP5HkD",
        "outputId": "ac3b4459-a5fa-4721-a098-c371663c8d08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epochs: 100%|██████████| 1000/1000 [14:49<00:00,  1.12it/s, accuracy=0.796]\n",
            "Epochs: 100%|██████████| 1000/1000 [14:40<00:00,  1.14it/s, accuracy=0.801]\n",
            "Epochs:  46%|████▌     | 457/1000 [06:39<07:27,  1.21it/s, accuracy=0.951]"
          ]
        }
      ],
      "source": [
        "for c in range(num_classes):\n",
        "    indceis=np.where(train_y==c)\n",
        "    train_y[:]=0\n",
        "    train_y[indceis]=1\n",
        "    model = LogisticRegression()\n",
        "    model.fit(x_train,train_y)  \n",
        "    weights[c, :] = model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5a9ofuo5KDL"
      },
      "outputs": [],
      "source": [
        "\n",
        "Z = np.dot(weights, x_test.T)  \n",
        "\n",
        "\n",
        "softmax_values = np.exp(Z) / np.sum(np.exp(Z), axis=0)\n",
        "\n",
        "\n",
        "predicted_classes = np.argmax(softmax_values, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtwqjuQN5MUc"
      },
      "outputs": [],
      "source": [
        "accuracy = np.mean(softmax_values == test_y)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
